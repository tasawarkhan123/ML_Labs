{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cef70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'G:\\Taswar_Khan_ML') \n",
    "from stlf_torch_kit import  DataLoadeing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time\n",
    "from stlf_torch_kit import univariate_multi_step\n",
    "from stlf_torch_kit import SaveBestModel, PlotLossCurves, LoadModel, train, TestModel, BatchGenerator, results\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc31f46",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2a9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6132, 29), (1752, 29), (876, 29))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path_dataset =r'G:\\Taswar_Khan_ML\\Dataset'\n",
    "path_tr = os.path.join(path_dataset, 'CityLearn_train.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.iloc[:].values\n",
    "path_v = os.path.join(path_dataset, 'CityLearn_validation.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.iloc[:].values \n",
    "path_te = os.path.join(path_dataset, 'Citylearn_test.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.iloc[:].values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'Scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293ad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.06475687026977539 sec\n"
     ]
    }
   ],
   "source": [
    "time_steps = 24 \n",
    "target_len = 1 #how much steps do you wana forecast #Edit\n",
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=target_len)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=target_len)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=target_len)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc241223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 24, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52558d",
   "metadata": {},
   "source": [
    "#### LSTM_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1912c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, time_steps=24, num_features=29):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=num_features, hidden_size=64, batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, time_steps, num_features)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Only take the output of the last time step\n",
    "        x = x[:, -1, :]  # shape: (batch_size, 32)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.output_layer(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659def4",
   "metadata": {},
   "source": [
    "# instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel()#Edit\n",
    "criterion = nn.MSELoss() #Edit, don't change\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a217f",
   "metadata": {},
   "source": [
    "# Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9867523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=0.001 # Edit\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr) #Edit\n",
    "lr = 0.001  # Initial learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)  # Added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b55ecf",
   "metadata": {},
   "source": [
    "# Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53206b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "device = get_model_device(model)\n",
    "print(\"Model is on device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fafebb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa963e",
   "metadata": {},
   "source": [
    "#### Path & other Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3924df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 20 #Edit\n",
    "best_model_path=r'G:\\Taswar_Khan_ML\\chk'+str('\\\\') #Edit\n",
    "fig_path=r'G:\\Taswar_Khan_ML\\chk' #Edit\n",
    "train_data_loader, validation_data_loader, test_data_loader = DataLoadeing(train_X ,\n",
    "                                                                           train_y, \n",
    "                                                                           validation_X, \n",
    "                                                                           validation_y, \n",
    "                                                                           test_X, \n",
    "                                                                           test_y, \n",
    "                                                                           batch_size=32) #Batch_Size Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460874b",
   "metadata": {},
   "source": [
    "#### Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b17e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Edit, for Now Don't  Change\n",
    "\n",
    "criterion_mae = nn.L1Loss()\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bee91",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37aa742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [191/191], Training Loss: 0.0489\n",
      "Epoch [1/20], Step [54/54], Val Loss: 0.0404\n",
      "\n",
      "Saving best model for epoch: 1\n",
      " at G:\\Taswar_Khan_ML\\chk\\1best_model.pth\n",
      "Epoch [2/20], Step [191/191], Training Loss: 0.0412\n",
      "Epoch [2/20], Step [54/54], Val Loss: 0.0404\n",
      "\n",
      "Saving best model for epoch: 2\n",
      " at G:\\Taswar_Khan_ML\\chk\\2best_model.pth\n",
      "Epoch [3/20], Step [191/191], Training Loss: 0.0389\n",
      "Epoch [3/20], Step [54/54], Val Loss: 0.0406\n",
      "Epoch [4/20], Step [191/191], Training Loss: 0.0373\n",
      "Epoch [4/20], Step [54/54], Val Loss: 0.0413\n",
      "Epoch [5/20], Step [191/191], Training Loss: 0.0363\n",
      "Epoch [5/20], Step [54/54], Val Loss: 0.0419\n",
      "Epoch [6/20], Step [191/191], Training Loss: 0.0353\n",
      "Epoch [6/20], Step [54/54], Val Loss: 0.0417\n",
      "Epoch [7/20], Step [191/191], Training Loss: 0.0339\n",
      "Epoch [7/20], Step [54/54], Val Loss: 0.0428\n",
      "Epoch [8/20], Step [191/191], Training Loss: 0.0327\n",
      "Epoch [8/20], Step [54/54], Val Loss: 0.0417\n",
      "Epoch [9/20], Step [191/191], Training Loss: 0.0312\n",
      "Epoch [9/20], Step [54/54], Val Loss: 0.0409\n",
      "Epoch [10/20], Step [191/191], Training Loss: 0.0288\n",
      "Epoch [10/20], Step [54/54], Val Loss: 0.0396\n",
      "\n",
      "Saving best model for epoch: 10\n",
      " at G:\\Taswar_Khan_ML\\chk\\10best_model.pth\n",
      "Epoch [11/20], Step [191/191], Training Loss: 0.0278\n",
      "Epoch [11/20], Step [54/54], Val Loss: 0.0374\n",
      "\n",
      "Saving best model for epoch: 11\n",
      " at G:\\Taswar_Khan_ML\\chk\\11best_model.pth\n",
      "Epoch [12/20], Step [191/191], Training Loss: 0.0259\n",
      "Epoch [12/20], Step [54/54], Val Loss: 0.0360\n",
      "\n",
      "Saving best model for epoch: 12\n",
      " at G:\\Taswar_Khan_ML\\chk\\12best_model.pth\n",
      "Epoch [13/20], Step [191/191], Training Loss: 0.0249\n",
      "Epoch [13/20], Step [54/54], Val Loss: 0.0337\n",
      "\n",
      "Saving best model for epoch: 13\n",
      " at G:\\Taswar_Khan_ML\\chk\\13best_model.pth\n",
      "Epoch [14/20], Step [191/191], Training Loss: 0.0237\n",
      "Epoch [14/20], Step [54/54], Val Loss: 0.0321\n",
      "\n",
      "Saving best model for epoch: 14\n",
      " at G:\\Taswar_Khan_ML\\chk\\14best_model.pth\n",
      "Epoch [15/20], Step [191/191], Training Loss: 0.0230\n",
      "Epoch [15/20], Step [54/54], Val Loss: 0.0314\n",
      "\n",
      "Saving best model for epoch: 15\n",
      " at G:\\Taswar_Khan_ML\\chk\\15best_model.pth\n",
      "Epoch [16/20], Step [191/191], Training Loss: 0.0223\n",
      "Epoch [16/20], Step [54/54], Val Loss: 0.0302\n",
      "\n",
      "Saving best model for epoch: 16\n",
      " at G:\\Taswar_Khan_ML\\chk\\16best_model.pth\n",
      "Epoch [17/20], Step [191/191], Training Loss: 0.0219\n",
      "Epoch [17/20], Step [54/54], Val Loss: 0.0305\n",
      "Epoch [18/20], Step [191/191], Training Loss: 0.0213\n",
      "Epoch [18/20], Step [54/54], Val Loss: 0.0297\n",
      "\n",
      "Saving best model for epoch: 18\n",
      " at G:\\Taswar_Khan_ML\\chk\\18best_model.pth\n",
      "Epoch [19/20], Step [191/191], Training Loss: 0.0213\n",
      "Epoch [19/20], Step [54/54], Val Loss: 0.0309\n",
      "Epoch [20/20], Step [191/191], Training Loss: 0.0208\n",
      "Epoch [20/20], Step [54/54], Val Loss: 0.0315\n",
      "Time Consumed 167.40857005119324 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c897f0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e071d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.001\n",
      "Time Consumed 0.2932155132293701 sec\n",
      "Mean Absolute Error (MAE): 0.39\n",
      "Median Absolute Error (MedAE): 0.29\n",
      "Mean Squared Error (MSE): 0.26\n",
      "Root Mean Squared Error (RMSE): 0.51\n",
      "Mean Absolute Percentage Error (MAPE): 62.45 %\n",
      "Median Absolute Percentage Error (MDAPE): 42.45 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (851, 1)\n",
      "y_pred.shape=  (851, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'G:\\Taswar_Khan_ML\\chk\\18best_model.pth' # Edit\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)\n",
    "\n",
    "# MAPE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ff80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
